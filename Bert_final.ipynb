{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6838dc3-b606-4d0e-9280-0ae543b01224",
   "metadata": {},
   "source": [
    "### Описание проекта\n",
    "Проект для «Викишоп» с BERT.\n",
    "\n",
    "Описание исследования: Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию\n",
    "\n",
    "Цель исследования: Обучить модель классифицировать комментарии на позитивные и негативные на основе набора данных с разметкой о токсичности правок.\n",
    "\n",
    "Критерии, которые важны заказчику:\n",
    "Построить модель со значением метрики качества F1 не меньше 0.75.\n",
    "\n",
    "Задачи исследования:\n",
    "\n",
    "Загрузить данные.\n",
    "Проанализировать данные.\n",
    "Обучить разные модели с различными гиперпараметрами. \n",
    "Проверить данные на тестовой выборке и сделать выводы.\n",
    "\n",
    "Данное исследование разделим на несколько частей.\n",
    "\n",
    "Часть 1. Изучениеm общей информации:\n",
    "\n",
    "Изучение файлов с данными, получение общей информации, загрузка библиотек. \n",
    "\n",
    "Часть 2. Подготовка данных:\n",
    "\n",
    "Нахождение и ликвидация пропусков. Проверка и ликвидация дубликатов. Исследовательский анализ данных.\n",
    "\n",
    "Часть 3. Обучение моделей:\n",
    "\n",
    "Обучение моделей LightGBM, LogisticRegression, DesicionTreeClassifier, KNN. Нахождение лучшей модели по метрике F1 на кросс-валидации.\n",
    "\n",
    "Часть 4. Тестирование лучшей модели на тестовой выборке и итоговые выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba38d7bb-14ca-40fd-be33-3d93b8c6a1cc",
   "metadata": {},
   "source": [
    "#### 1. Изучение общей информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c54fda6-a37c-407f-9088-0c07d318e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc78c93-5b67-4252-a1a8-73038fee8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ba72d6-fb90-461c-a01c-a6439d2a0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c9fc0f-0231-4759-93f8-7ed029ab6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22062a87-87a4-407c-a452-04a7f7987a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa21829-a5c9-4e58-8977-ceb36cb80ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('C:\\\\Users\\\\N\\\\Documents\\\\Документы\\\\Data science\\\\МО для текстов\\\\toxic_comments.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa454d-933d-4d35-ae6c-c32e53707e70",
   "metadata": {},
   "source": [
    "#### 2. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd732006-05e8-4a26-8f2b-a390e9143a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b070c50c-fbcd-4770-a0da-8d5b37e64051",
   "metadata": {},
   "source": [
    " Пропусков в данных нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00a6b068-c469-416b-8a62-e2f52ab79d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75d1b6e-1928-4190-9785-a10cda1f4bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9299a6b-8dfa-4008-a2c8-c9f65188288b",
   "metadata": {},
   "source": [
    "Полных и неполных дубликатов в данных нет. Проверим целевой признак на сбалансированность классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49646fd4-6fab-46ba-a816-4b2d2753adab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts(normalize=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e32a17-90f4-4afa-9aed-e0d5ffe2777f",
   "metadata": {},
   "source": [
    "Данные очевидно несбалансированы. Это будет необходимо учесть при делении выбоки на обучающую и тестовую."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd5f29-a6ca-4736-9033-0c0f9db2d39d",
   "metadata": {},
   "source": [
    "Построим векторы текстов с помощью предобученной модели BERT.\n",
    "Для применения модели Bert необходимо уменьшить размер выборки, иначе она будет очень долго обрабатываться.\n",
    "Для корректной работы модели необходимо, чтобы количество токенов было не более 512, для этого оставим в выборке только строки с количеством символов не более 1800 (тк одно слово обычно содержит около 3-4 токенов) и выберем из них 2000 произвольных строк (пробовала 10000 строк - считалось 1,5 часа и метрика F1 получалась лучше на 0.01-0.02 на кросс-валидации и тестовой выборке соответственно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072d99e5-9538-4ac1-a38a-84c4ba6d764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len'] = data['text'].str.len()\n",
    "data_bert = data.query('len < 1800')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c080846d-54b3-4768-87e5-4252edc4dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_bert = data_bert.sample(2000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fcf55-0af4-4010-8334-1017c0551328",
   "metadata": {},
   "source": [
    "Применим предобученную модель 'unitary/toxic-bert'.\n",
    "Инициализируем токенизатор как объект класса BertTokenizer.\n",
    "Преобразуем текст в номера токенов из словаря методом encode().\n",
    "Применим метод padded, чтобы после токенизации длины исходных текстов в корпусе были равными. \n",
    "Отбросим нулевые токены и «создадим маску» для действительно важных токенов, то есть укажем нулевые и не нулевые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aad92509-f0d1-42ec-9f4c-9f7d82082d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 447)\n",
      "(2000, 447)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "\n",
    "tokenized = data_bert['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "print(padded.shape)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3636758-d2ad-4450-a6f2-7854f1f30747",
   "metadata": {},
   "source": [
    "Инициализируем конфигурацию BertConfig. Передадим ей файл с предобученной моделью и конфигурацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce12c82c-43a3-447e-903f-ba19c13ae228",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained('unitary/toxic-bert')\n",
    "model = BertModel.from_pretrained('unitary/toxic-bert', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af6297-c5a4-4377-bfb5-6673b55de923",
   "metadata": {},
   "source": [
    "Преобразуем текст в эмбеддинги.\n",
    "Чтобы хватило оперативной памяти, сделаем размер батча 100.\n",
    "Преобразуем данные в формат тензоров - многомерных векторов в библиотеке torch.\n",
    "Передадим модели данные и маску. \n",
    "Для ускорения вычисления функцией no_grad() в библиотеке torch укажем, что градиенты не нужны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c5bd1c3-8626-4688-8678-257a445cd947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7cf67ca34643dba449e90bd244ae68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c684d-f725-4ac7-9923-f3d3a36b1f4c",
   "metadata": {},
   "source": [
    "Соберём все эмбеддинги в матрицу признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1352a880-2dca-4516-81bc-4598b93dd8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38659cb6-e5f6-45a1-a269-53407b7ec7aa",
   "metadata": {},
   "source": [
    "Разделим выборку на обучающую и тестовую с учетом стратификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "839c6ef8-f1d3-4e64-b31f-10823686f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    data_bert['toxic'],\n",
    "    test_size = 0.25, \n",
    "    random_state = 42, stratify=data_bert['toxic'])\n",
    "model=LogisticRegression(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfc040-a962-411c-b615-aa474ab7d38a",
   "metadata": {},
   "source": [
    "#### 3. Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16990b70-0829-4033-b0ae-109566dbd945",
   "metadata": {},
   "source": [
    "Обучим 4 разных модели: KNN, DecisionTreeClassifier, LogisticRegression, LightGBM, с помощью пайплайна зададим разные гиперпараметры и применим RandomSearchCV для поиска лучшей метрики F1_score на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b25f73d8-e093-4706-ab85-5d88c2e86898",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_final = Pipeline([\n",
    "    #('preprocessor', data_preprocessor),\n",
    "    ('models', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb301c1-16bf-43ec-9c6e-c7db18909ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = [\n",
    "    \n",
    "    {\n",
    "        'models': [KNeighborsClassifier()],\n",
    "        'models__n_neighbors': range(2,7),\n",
    "           \n",
    "    },\n",
    "   \n",
    "    {\n",
    "        'models': [DecisionTreeClassifier(random_state=RANDOM_STATE)],\n",
    "        'models__max_depth': range(2, 10),\n",
    "        'models__min_samples_leaf': range(1, 6),\n",
    "        'models__min_samples_split': range(2, 6),\n",
    "           \n",
    "    },\n",
    "        \n",
    "   \n",
    "    {\n",
    "        'models': [LogisticRegression(random_state=RANDOM_STATE, solver='liblinear')],\n",
    "        'models__C': range(1,5),\n",
    "        'model__penalty': ['l1', 'l2']\n",
    "       },\n",
    "    {\n",
    "\n",
    "         'models': [lgb.LGBMRegressor(learning_rate=0.1, random_state=RANDOM_STATE)],\n",
    "         'models__n_estimators': [100,300],\n",
    "         'models__max_depth': range(1,3),\n",
    "    }\n",
    "\n",
    "        \n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f14fbc3e-90c4-4677-b4e4-51d4333f7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_search = RandomizedSearchCV(\n",
    "    pipe_final, \n",
    "    param_distributions, \n",
    "    cv=5,\n",
    "    scoring='f1', \n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dab4bca3-67b2-4f01-852c-99718b558abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.91615602 0.91098492 0.91977184 0.91987751 0.91098492 0.92682343\n",
      " 0.91977184        nan 0.91146122 0.91977184]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и её параметры:\n",
      "\n",
      " Pipeline(steps=[('models',\n",
      "                 DecisionTreeClassifier(max_depth=2, min_samples_leaf=3,\n",
      "                                        min_samples_split=5,\n",
      "                                        random_state=42))])\n",
      "Метрика лучшей модели на кросс-валидации: {'models__min_samples_split': 5, 'models__min_samples_leaf': 3, 'models__max_depth': 2, 'models': DecisionTreeClassifier(max_depth=2, min_samples_leaf=3, min_samples_split=5,\n",
      "                       random_state=42)}\n",
      "Метрика лучшей модели на кросс-валидации: 0.93\n"
     ]
    }
   ],
   "source": [
    "randomized_search.fit(X_train, y_train)\n",
    "print('Лучшая модель и её параметры:\\n\\n', randomized_search.best_estimator_)\n",
    "print ('Метрика лучшей модели на кросс-валидации:', randomized_search.best_params_)\n",
    "print ('Метрика лучшей модели на кросс-валидации:', round(randomized_search.best_score_,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06b74a-39ff-40d0-8326-aa4c9d7f2c61",
   "metadata": {},
   "source": [
    "Итак, лучшая модель - DecisionTreeClassifier(max_depth=3, min_samples_leaf=2, min_samples_split=3,random_state=42) с метрикой F1=0.93.\n",
    "Протестируем данную модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e571e-8ac7-4669-9e86-c40894be8ce0",
   "metadata": {},
   "source": [
    "#### 4. Тестирование лучшей модели на тестовой выборке и итоговые выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b0b3311-3f07-4147-af8c-eb4688bedee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.92\n"
     ]
    }
   ],
   "source": [
    "model_best = randomized_search.best_estimator_\n",
    "predictions = model_best.predict(X_test)\n",
    "f1_test = f1_score(y_test, predictions)\n",
    "print(f\"F1 на тестовой выборке: {f1_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df93d3e-9f34-4034-88b0-45b64bfd6829",
   "metadata": {},
   "source": [
    "Итак, в соответствии с задачами исследования были проделаны следующие этапы работы:\n",
    "\n",
    "Загружены данные, загружены необходимые библиотеки.\n",
    "\n",
    "Данные были проанализированы на предмет пропусков и дубликатов (не выявлено). Но был выявлен дисбаланс классов в целевом признаке - 90:10%.\n",
    "\n",
    "Были построены векторы текстов с помощью предобученной модели 'unitary/toxic-bert'.\n",
    "Тестовая выборка была стратифицирована наравне с обучающей.\n",
    "\n",
    "Были обучены модели LightGBM, LogisticRegression, DesicionTreeClassifier, KNN с различными гиперпараметрами. \n",
    "По итогам расчета метрики F1= 0.93 на кросс-валидации была выбрана лучшая модель - DecisionTreeClassifier(max_depth=3, min_samples_leaf=2,\n",
    "                                        min_samples_split=3, random_state=42))\n",
    "\n",
    "На тестовой выборке данная модель показала результат F1=0.92, что полностью соответсвует критерию заказчика (построить модель со значением метрики качества F1 не меньше 0.75)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
